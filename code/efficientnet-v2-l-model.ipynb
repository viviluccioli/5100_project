{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSegb-ar5T0U"
      },
      "source": [
        "# EfficientNet-V2-L Hair Type Classifier\n",
        "\n",
        "This notebook trains a hair type classifier using EfficientNet-V2-L with mixed precision training.\n",
        "\n",
        "## Setup Instructions\n",
        "1. **Enable GPU**: Go to `Runtime` ‚Üí `Change runtime type` ‚Üí Select `GPU` (preferably T4 or better)\n",
        "2. **Upload your data** to Google Drive in this structure:\n",
        "```\n",
        "MyDrive/\n",
        "‚îî‚îÄ‚îÄ hair_data/\n",
        "    ‚îî‚îÄ‚îÄ segmented/\n",
        "        ‚îú‚îÄ‚îÄ 1/\n",
        "        ‚îú‚îÄ‚îÄ 2a/\n",
        "        ‚îú‚îÄ‚îÄ 2b/\n",
        "        ‚îî‚îÄ‚îÄ ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV3Bt1OD5T0U"
      },
      "source": [
        "## 1. Mount Google Drive & Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktFx-lpY5T0V",
        "outputId": "b1bf1fe7-43cd-4d29-f1b9-be9948056110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9DYzsFu5T0V",
        "outputId": "6c097b90-1b41-4738-9ecf-0d940dd187ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU Available: Tesla T4\n",
            "   Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
        "    print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "    raise RuntimeError(\"GPU required for training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UcAeasg5T0V"
      },
      "source": [
        "## 2. Configuration\n",
        "\n",
        "‚ö†Ô∏è **Update `DATA_DIR` to match your Google Drive path!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaSEThfp5T0V",
        "outputId": "3efa2b63-9aad-401b-e195-1cd3cf90b487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import efficientnet_v2_l, EfficientNet_V2_L_Weights\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# CONFIGURATION - UPDATE THESE PATHS!\n",
        "# ============================================================\n",
        "DATA_DIR = \"/content/drive/MyDrive/hair_data/segmented/\"  # ‚Üê Update this!\n",
        "OUTPUT_DIR = \"/content/split/\"                            # Local split folder\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/hair_data/checkpoints/\"  # Save to Drive\n",
        "\n",
        "# Training parameters\n",
        "IMG_SIZE = 600          # Reduced from 600 to fit in GPU memory\n",
        "BATCH_SIZE = 2\n",
        "ACCUMULATION_STEPS = 16  # Effective = 32\n",
        "EPOCHS = 20\n",
        "LR = 3e-4\n",
        "\n",
        "# Data split ratios\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# Resume training from checkpoint?\n",
        "RESUME_FROM_CHECKPOINT = True\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QVRpvq95T0V",
        "outputId": "5fd1130d-e31b-4a00-dde2-e9bac276cec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found data directory with 10 classes: ['1', '2a', '2b', '2c', '3a', '3b', '3c', '4a', '4b', '4c']\n"
          ]
        }
      ],
      "source": [
        "# Verify data directory exists\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n",
        "    print(\"\\nPlease update DATA_DIR in the cell above to match your Google Drive path.\")\n",
        "    raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\")\n",
        "else:\n",
        "    classes = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
        "    print(f\"‚úÖ Found data directory with {len(classes)} classes: {sorted(classes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcFL0ZLG5T0V"
      },
      "source": [
        "## 3. Split Dataset into Train/Val/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uaj9gk9y5T0V"
      },
      "outputs": [],
      "source": [
        "def split_dataset(source_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Split images from class folders into train/val/test structure.\n",
        "\n",
        "    Expected input structure:\n",
        "        source_dir/\n",
        "        ‚îú‚îÄ‚îÄ 1/\n",
        "        ‚îú‚îÄ‚îÄ 2a/\n",
        "        ‚îú‚îÄ‚îÄ 2b/\n",
        "        ‚îî‚îÄ‚îÄ ...\n",
        "\n",
        "    Output structure:\n",
        "        output_dir/\n",
        "        ‚îú‚îÄ‚îÄ train/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ 1/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ 2a/\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "        ‚îú‚îÄ‚îÄ val/\n",
        "        ‚îî‚îÄ‚îÄ test/\n",
        "    \"\"\"\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1\"\n",
        "\n",
        "    # Create output directories\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(output_dir, split)\n",
        "        if os.path.exists(split_path):\n",
        "            shutil.rmtree(split_path)\n",
        "        os.makedirs(split_path)\n",
        "\n",
        "    # Get class folders\n",
        "    classes = [d for d in os.listdir(source_dir)\n",
        "               if os.path.isdir(os.path.join(source_dir, d))]\n",
        "    classes.sort()\n",
        "    print(f\"Found {len(classes)} classes: {classes}\")\n",
        "\n",
        "    stats = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(source_dir, cls)\n",
        "        images = [f for f in os.listdir(cls_path)\n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        if len(images) < 3:\n",
        "            print(f\"‚ö†Ô∏è  Warning: Class '{cls}' has only {len(images)} images\")\n",
        "            continue\n",
        "\n",
        "        # Split: first into train and temp, then temp into val and test\n",
        "        train_imgs, temp_imgs = train_test_split(\n",
        "            images, train_size=train_ratio, random_state=42, shuffle=True\n",
        "        )\n",
        "        relative_val = val_ratio / (val_ratio + test_ratio)\n",
        "        val_imgs, test_imgs = train_test_split(\n",
        "            temp_imgs, train_size=relative_val, random_state=42, shuffle=True\n",
        "        )\n",
        "\n",
        "        # Copy images to respective folders\n",
        "        for split, img_list in [('train', train_imgs), ('val', val_imgs), ('test', test_imgs)]:\n",
        "            split_cls_path = os.path.join(output_dir, split, cls)\n",
        "            os.makedirs(split_cls_path, exist_ok=True)\n",
        "            for img in img_list:\n",
        "                src = os.path.join(cls_path, img)\n",
        "                dst = os.path.join(split_cls_path, img)\n",
        "                shutil.copy2(src, dst)\n",
        "            stats[cls][split] = len(img_list)\n",
        "\n",
        "    # Print statistics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Dataset Split Statistics\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"{'Class':<10} {'Train':<10} {'Val':<10} {'Test':<10} {'Total':<10}\")\n",
        "    print(\"-\" * 50)\n",
        "    total_train, total_val, total_test = 0, 0, 0\n",
        "    for cls in classes:\n",
        "        total = stats[cls]['train'] + stats[cls]['val'] + stats[cls]['test']\n",
        "        total_train += stats[cls]['train']\n",
        "        total_val += stats[cls]['val']\n",
        "        total_test += stats[cls]['test']\n",
        "        print(f\"{cls:<10} {stats[cls]['train']:<10} {stats[cls]['val']:<10} {stats[cls]['test']:<10} {total:<10}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'TOTAL':<10} {total_train:<10} {total_val:<10} {total_test:<10} {total_train+total_val+total_test:<10}\")\n",
        "\n",
        "    return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k314yzto5T0V",
        "outputId": "cebaea06-78dc-48a0-f698-e1c22816d725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Splitting Dataset ===\n",
            "Found 10 classes: ['1', '2a', '2b', '2c', '3a', '3b', '3c', '4a', '4b', '4c']\n",
            "\n",
            "==================================================\n",
            "Dataset Split Statistics\n",
            "==================================================\n",
            "Class      Train      Val        Test       Total     \n",
            "--------------------------------------------------\n",
            "1          1297       278        278        1853      \n",
            "2a         1511       324        324        2159      \n",
            "2b         839        180        180        1199      \n",
            "2c         838        180        180        1198      \n",
            "3a         836        179        180        1195      \n",
            "3b         848        182        182        1212      \n",
            "3c         969        208        208        1385      \n",
            "4a         1209       259        260        1728      \n",
            "4b         1402       301        301        2004      \n",
            "4c         1614       346        347        2307      \n",
            "--------------------------------------------------\n",
            "TOTAL      11363      2437       2440       16240     \n"
          ]
        }
      ],
      "source": [
        "# Run the split\n",
        "print(\"=== Splitting Dataset ===\")\n",
        "CLASS_NAMES = split_dataset(DATA_DIR, OUTPUT_DIR, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CnOdtL95T0V"
      },
      "source": [
        "## 4. Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD-2qV0y5T0V",
        "outputId": "108ca9ac-4303-4472-a690-27773f829ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Detected 10 classes: ['1', '2a', '2b', '2c', '3a', '3b', '3c', '4a', '4b', '4c']\n",
            "   Train: 11363 images\n",
            "   Val:   2437 images\n",
            "   Test:  2440 images\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation for training\n",
        "train_tfms = transforms.Compose([\n",
        "    # No resize needed ‚Äî already 600x600\n",
        "    transforms.RandomHorizontalFlip(),  # Keep ‚Äî nearly free, helps generalization\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Validation/test transforms (no augmentation)\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, \"train\"), train_tfms)\n",
        "val_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, \"val\"), val_tfms)\n",
        "test_ds = datasets.ImageFolder(os.path.join(OUTPUT_DIR, \"test\"), val_tfms)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "print(f\"\\n‚úÖ Detected {num_classes} classes: {train_ds.classes}\")\n",
        "print(f\"   Train: {len(train_ds)} images\")\n",
        "print(f\"   Val:   {len(val_ds)} images\")\n",
        "print(f\"   Test:  {len(test_ds)} images\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9KNRspe5T0W"
      },
      "source": [
        "## 5. Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xliapZdB5T0W",
        "outputId": "65793bb7-3cd1-4875-955d-7bd0d9a8a26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading EfficientNet-V2-L with ImageNet weights...\n",
            "\n",
            "‚úÖ Model loaded successfully\n",
            "   Total parameters: 117,247,082\n",
            "   Trainable parameters: 117,247,082\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained EfficientNet-V2-L\n",
        "print(\"Loading EfficientNet-V2-L with ImageNet weights...\")\n",
        "weights = EfficientNet_V2_L_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_v2_l(weights=weights)\n",
        "\n",
        "# Replace classifier head for our number of classes\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n‚úÖ Model loaded successfully\")\n",
        "print(f\"   Total parameters: {total_params:,}\")\n",
        "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Loss, optimizer, scaler, scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "scaler = GradScaler('cuda')\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09vJ0xjz5T0W"
      },
      "source": [
        "## 6. Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "L4zJiKqk5T0W"
      },
      "outputs": [],
      "source": [
        "def validate(loader, desc=\"Validating\"):\n",
        "    \"\"\"Compute loss and accuracy on a data loader.\"\"\"\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    running_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(loader, desc=desc, leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in pbar:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += len(labels)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            pbar.set_postfix({'acc': f'{correct/total:.4f}'})\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
        "\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    \"\"\"Train for one epoch with gradient accumulation.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch:02d} Training\", leave=False)\n",
        "\n",
        "    for i, (imgs, labels) in enumerate(pbar):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels) / ACCUMULATION_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % ACCUMULATION_STEPS == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item() * ACCUMULATION_STEPS\n",
        "\n",
        "        pbar.set_postfix({'loss': f'{running_loss/(i+1):.4f}'})\n",
        "\n",
        "    return running_loss / len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3cLmS8gt5T0W"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(epoch, model, optimizer, scaler, best_val_acc, history):\n",
        "    \"\"\"Save training checkpoint.\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict(),\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'history': history,\n",
        "    }\n",
        "    torch.save(checkpoint, os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pth'))\n",
        "    print(f\"Checkpoint saved\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, scaler, scheduler):\n",
        "    \"\"\"Load training checkpoint if it exists.\"\"\"\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'latest_checkpoint.pth')\n",
        "    if os.path.exists(checkpoint_path) and RESUME_FROM_CHECKPOINT:\n",
        "        print(f\"Found checkpoint at {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "        if 'scheduler_state_dict' in checkpoint:\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_val_acc = checkpoint['best_val_acc']\n",
        "        history = checkpoint['history']\n",
        "        print(f\"‚úÖ Resumed from epoch {checkpoint['epoch']} (best val acc: {best_val_acc:.4f})\")\n",
        "        return start_epoch, best_val_acc, history\n",
        "\n",
        "    print(\"Starting fresh training (no checkpoint found or resume disabled)\")\n",
        "    return 1, 0.0, {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'lr': []}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9tsmImT5T0W"
      },
      "source": [
        "## 7. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641,
          "referenced_widgets": [
            "40326fdf02d54cbc9bc82040c62c1172",
            "bcfc0665fc7b436db6c1f633d1a7c59c",
            "c6dcb0bcc6b2472c894334da2a94d746",
            "254145b1e5e24366aebd80f89f86eb49",
            "e1b7ce3a60d0489381b6025b3ea82248",
            "b3dffede13da48749b7b6056a8593679",
            "2b288d178d07444db7ba102937237372",
            "54d77136d0c144b18c972790d9158f3d",
            "7c5f23685b494f859d660150729f419a",
            "9357b40835ef4d2fb51abeab2230091f",
            "6d0a31978a9b47f8a33212d8b4983b9c"
          ]
        },
        "id": "KP6LFdCK5T0W",
        "outputId": "53115540-2717-497e-fb17-5cf5c8a32751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fresh training (no checkpoint found or resume disabled)\n",
            "\n",
            "============================================================\n",
            "Starting Training\n",
            "============================================================\n",
            "Epochs: 1 to 20\n",
            "Batch size: 2 (effective: 32)\n",
            "Learning rate: 0.0003 (with cosine annealing)\n",
            "Image size: 600x600\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 01 Training:   0%|          | 0/1894 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40326fdf02d54cbc9bc82040c62c1172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 7698 has 14.73 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 633.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-904066755.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-267416966.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 7698 has 14.73 GiB memory in use. Of the allocated memory 13.98 GiB is allocated by PyTorch, and 633.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "start_epoch, best_val_acc, history = load_checkpoint(model, optimizer, scaler, scheduler)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Starting Training\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Epochs: {start_epoch} to {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * ACCUMULATION_STEPS})\")\n",
        "print(f\"Learning rate: {LR} (with cosine annealing)\")\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS + 1):\n",
        "    start = time.time()\n",
        "\n",
        "    # Get current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_one_epoch(epoch)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc, val_f1, _, _ = validate(val_loader)\n",
        "\n",
        "    # Step scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    duration = time.time() - start\n",
        "\n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    history['lr'].append(current_lr)\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | \"\n",
        "          f\"Val Acc: {val_acc:.4f} | \"\n",
        "          f\"Val F1: {val_f1:.4f} | \"\n",
        "          f\"LR: {current_lr:.2e} | \"\n",
        "          f\"Time: {duration:.1f}s\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        ckpt_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        print(f\"  ‚úÖ New best model saved! (acc: {best_val_acc:.4f})\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(epoch, model, optimizer, scaler, scheduler, best_val_acc, history)\n",
        "    print(f\"  üíæ Checkpoint saved\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training Complete!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6cZ6D7-5T0W"
      },
      "source": [
        "## 8. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LGKg25Z5T0W"
      },
      "outputs": [],
      "source": [
        "print(\"=== Evaluating on Test Set ===\")\n",
        "\n",
        "# Load best model\n",
        "best_model_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "if os.path.exists(best_model_path):\n",
        "    model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
        "    print(f\"Loaded best model from {best_model_path}\")\n",
        "else:\n",
        "    print(\"Using current model (no best_model.pth found)\")\n",
        "\n",
        "test_loss, test_acc, test_f1, test_preds, test_labels = validate(test_loader)\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"Test Results\")\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.1f}%)\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"{'='*40}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv_TN1I25T0W"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMcx1b-i5T0W"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Hair Type Classification')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'confusion_matrix.png'), dpi=150)\n",
        "plt.show()\n",
        "print(f\"Saved to {CHECKPOINT_DIR}/confusion_matrix.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGzGzPkn5T0W"
      },
      "source": [
        "## 9. Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NypU-Yk5T0W"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "epochs_range = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(epochs_range, history['train_loss'], label='Train Loss', marker='o')\n",
        "axes[0].plot(epochs_range, history['val_loss'], label='Val Loss', marker='o')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training vs Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(epochs_range, history['val_acc'], label='Val Accuracy', color='green', marker='o')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Validation Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# F1 Score\n",
        "axes[2].plot(epochs_range, history['val_f1'], label='Val F1', color='orange', marker='o')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('F1 Score')\n",
        "axes[2].set_title('Validation F1 Score')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CHECKPOINT_DIR, 'training_history.png'), dpi=150)\n",
        "plt.show()\n",
        "print(f\"Saved to {CHECKPOINT_DIR}/training_history.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T-w-Wcm5T0W"
      },
      "source": [
        "## 10. Inference Helper (Optional)\n",
        "\n",
        "Use this to predict on new images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6a6aKi85T0W"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_hair_type(image_path, model, class_names, device='cuda'):\n",
        "    \"\"\"Predict hair type from an image path.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Load and transform image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(img_tensor)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            pred_idx = outputs.argmax(dim=1).item()\n",
        "\n",
        "    pred_class = class_names[pred_idx]\n",
        "    confidence = probs[0, pred_idx].item()\n",
        "\n",
        "    return pred_class, confidence, probs[0].cpu().numpy()\n",
        "\n",
        "\n",
        "# Example usage (uncomment and modify path):\n",
        "# image_path = \"/content/drive/MyDrive/test_image.jpg\"\n",
        "# pred_class, conf, all_probs = predict_hair_type(image_path, model, CLASS_NAMES)\n",
        "# print(f\"Predicted: {pred_class} (confidence: {conf:.2%})\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40326fdf02d54cbc9bc82040c62c1172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcfc0665fc7b436db6c1f633d1a7c59c",
              "IPY_MODEL_c6dcb0bcc6b2472c894334da2a94d746",
              "IPY_MODEL_254145b1e5e24366aebd80f89f86eb49"
            ],
            "layout": "IPY_MODEL_e1b7ce3a60d0489381b6025b3ea82248"
          }
        },
        "bcfc0665fc7b436db6c1f633d1a7c59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dffede13da48749b7b6056a8593679",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b288d178d07444db7ba102937237372",
            "value": "Epoch‚Äá01‚ÄáTraining:‚Äá‚Äá‚Äá0%"
          }
        },
        "c6dcb0bcc6b2472c894334da2a94d746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d77136d0c144b18c972790d9158f3d",
            "max": 1894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c5f23685b494f859d660150729f419a",
            "value": 0
          }
        },
        "254145b1e5e24366aebd80f89f86eb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9357b40835ef4d2fb51abeab2230091f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6d0a31978a9b47f8a33212d8b4983b9c",
            "value": "‚Äá0/1894‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "e1b7ce3a60d0489381b6025b3ea82248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3dffede13da48749b7b6056a8593679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b288d178d07444db7ba102937237372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d77136d0c144b18c972790d9158f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5f23685b494f859d660150729f419a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9357b40835ef4d2fb51abeab2230091f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0a31978a9b47f8a33212d8b4983b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}